[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a data scientist working in biotech. I’m hoping to post more regularly and share some of the cool things i’ve learned over the years."
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "",
    "text": "import warnings\nwarnings.filterwarnings('ignore')\nimport plotly.io as pio\nimport matplotlib.pyplot as plt\nimport plotly.express as px \nimport seaborn as sns\nplt.style.use('ggplot')\npio.templates.default = \"ggplot2\""
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#intro",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#intro",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "Intro",
    "text": "Intro\n\nWhat is Pandas?\n\npandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n\n\n\nWhat is Plotly?\nAn interactive ploting library for Python\n\n\nWhat is Seaborn?\nA data visualization tool (usually static) built on top of matplotlib\n\n\nWho is this for?\n\nNovice Analysts\nMed-Advanced Analysis Transitioning to Python\nSomeone who needs a refreser on the basics\n\n\n\nData Structures\n\n\nA DataFrame is made of Series structures\n\nA Series has a Row Names (index) and Column Names (columns) containing an array of the same value type (integer, float, string, etc..)"
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#data-munging",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#data-munging",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "Data Munging",
    "text": "Data Munging\n\nReading In Data\nWe’re going to explore a dataset that contains a variety of wines with written reviews, rating, price among other features.\n\nimport pandas as pd\ndf = pd.read_csv(\"data/winemag-data_first150k.csv\", index_col=0)\ndf.head()\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\n\n\n\n\n0\nUS\nThis tremendous 100% varietal wine hails from ...\nMartha's Vineyard\n96\n235.0\nCalifornia\nNapa Valley\nNapa\nCabernet Sauvignon\nHeitz\n\n\n1\nSpain\nRipe aromas of fig, blackberry and cassis are ...\nCarodorum Selección Especial Reserva\n96\n110.0\nNorthern Spain\nToro\nNaN\nTinta de Toro\nBodega Carmen Rodríguez\n\n\n2\nUS\nMac Watson honors the memory of a wine once ma...\nSpecial Selected Late Harvest\n96\n90.0\nCalifornia\nKnights Valley\nSonoma\nSauvignon Blanc\nMacauley\n\n\n3\nUS\nThis spent 20 months in 30% new French oak, an...\nReserve\n96\n65.0\nOregon\nWillamette Valley\nWillamette Valley\nPinot Noir\nPonzi\n\n\n4\nFrance\nThis is the top wine from La Bégude, named aft...\nLa Brûlade\n95\n66.0\nProvence\nBandol\nNaN\nProvence red blend\nDomaine de la Bégude\n\n\n\n\n\n\n\n\n\nData Types (dtypes)\n\nEach column must have a single type\n\nObject (strings, or any python object (like a list)\nFloating (float)\nInteger (int)\n\n\n\ndf.dtypes\n\ncountry         object\ndescription     object\ndesignation     object\npoints           int64\nprice          float64\nprovince        object\nregion_1        object\nregion_2        object\nvariety         object\nwinery          object\ndtype: object\n\n\n\nNote: Missing values are treated with a special NaN value, which is a float. This will convert your int dtypes to float if Pandas finds missing values in the column."
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#eda",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#eda",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "EDA",
    "text": "EDA\nExploring the data can get complicated. Pandas provides methods for exploration and processing tabular data.\n\n# Return the first 10 columns names\ndf.columns[:10]\n\nIndex(['country', 'description', 'designation', 'points', 'price', 'province',\n       'region_1', 'region_2', 'variety', 'winery'],\n      dtype='object')\n\n\n\n# Return the first 10 row names\ndf.index[:10]\n\nInt64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')\n\n\n\ndf.head(n=2)\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\n\n\n\n\n0\nUS\nThis tremendous 100% varietal wine hails from ...\nMartha's Vineyard\n96\n235.0\nCalifornia\nNapa Valley\nNapa\nCabernet Sauvignon\nHeitz\n\n\n1\nSpain\nRipe aromas of fig, blackberry and cassis are ...\nCarodorum Selección Especial Reserva\n96\n110.0\nNorthern Spain\nToro\nNaN\nTinta de Toro\nBodega Carmen Rodríguez\n\n\n\n\n\n\n\n\ndf.tail(n=2)\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\n\n\n\n\n150928\nFrance\nA perfect salmon shade, with scents of peaches...\nGrand Brut Rosé\n90\n52.0\nChampagne\nChampagne\nNaN\nChampagne Blend\nGosset\n\n\n150929\nItaly\nMore Pinot Grigios should taste like this. A r...\nNaN\n90\n15.0\nNortheastern Italy\nAlto Adige\nNaN\nPinot Grigio\nAlois Lageder\n\n\n\n\n\n\n\n\nColumn Selection\n\ndf['country'].head()\n\n0        US\n1     Spain\n2        US\n3        US\n4    France\nName: country, dtype: object\n\n\n\ndf[['country', 'points']].head() # Use lists for selecting multiple columns\n\n\n\n\n\n\n\n\ncountry\npoints\n\n\n\n\n0\nUS\n96\n\n\n1\nSpain\n96\n\n\n2\nUS\n96\n\n\n3\nUS\n96\n\n\n4\nFrance\n95\n\n\n\n\n\n\n\n\n\nFinding Data\nLoc Approach uses the indexes to locate the data you’re looking for.\n\ndf.loc[150929, 'country'] # Returns a string \n\n'Italy'\n\n\n\ndf.loc[150928:150930, 'country'] # Returns a series (of strings)\n\n150928    France\n150929     Italy\nName: country, dtype: object\n\n\n\ndf.loc[[150928, 150929], ['country', 'price']] # Returns a dataframe\n\n\n\n\n\n\n\n\ncountry\nprice\n\n\n\n\n150928\nFrance\n52.0\n\n\n150929\nItaly\n15.0\n\n\n\n\n\n\n\nIn many cases, we won’t know the index values that we’re looking for.\nWe’re often more interested in searching for specific values stored in one (or more) of the columns.\nHow would we do this?\n\n\nBoolean Masking\nEx: I want to know which rows in the country column equal Italy\nStep 1: Access the country Series object\nStep 2: Set an equality condition\n\ndf['country'] == 'Italy'\n\n0         False\n1         False\n2         False\n3         False\n4         False\n          ...  \n150925     True\n150926    False\n150927     True\n150928    False\n150929     True\nName: country, Length: 150930, dtype: bool\n\n\nThe result is a boolean series telling us which indexes equal “Italy”\nWe can transfer this operation into our .loc operation\n\nitalian_df = df.loc[(df['country'] == 'Italy')]\nitalian_df.head()\n# This contains a new copy of our dataframe with only Italy countries\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\n\n\n\n\n10\nItaly\nElegance, complexity and structure come togeth...\nRonco della Chiesa\n95\n80.0\nNortheastern Italy\nCollio\nNaN\nFriulano\nBorgo del Tiglio\n\n\n32\nItaly\nUnderbrush, scorched earth, menthol and plum s...\nVigna Piaggia\n90\nNaN\nTuscany\nBrunello di Montalcino\nNaN\nSangiovese\nAbbadia Ardenga\n\n\n35\nItaly\nForest floor, tilled soil, mature berry and a ...\nRiserva\n90\n135.0\nTuscany\nBrunello di Montalcino\nNaN\nSangiovese\nCarillon\n\n\n37\nItaly\nAromas of forest floor, violet, red berry and ...\nNaN\n90\n29.0\nTuscany\nVino Nobile di Montepulciano\nNaN\nSangiovese\nAvignonesi\n\n\n38\nItaly\nThis has a charming nose that boasts rose, vio...\nNaN\n90\n23.0\nTuscany\nChianti Classico\nNaN\nSangiovese\nCasina di Cornia\n\n\n\n\n\n\n\nThis is the most common way to search for data in Pandas.\nWe can combine boolean vectors using AND & and OR |\n\nit_or_fr = (df['country'] == 'Italy') | (df['country'] == 'France')\n\n\n# Show me wines from Italy OR France at or above the 95 percentile of the entire dataset\nexpensive_wine = df['price'] &gt; df['price'].quantile(.95)\n\n\n# Get me the rows where the row name is true for country italy or france and has expensive wine\ndf.loc[(it_or_fr) & (expensive_wine), ['country', 'variety', 'price', 'points']]\n\n\n\n\n\n\n\n\ncountry\nvariety\nprice\npoints\n\n\n\n\n13\nFrance\nTannat\n90.0\n95\n\n\n18\nFrance\nMalbec\n290.0\n95\n\n\n35\nItaly\nSangiovese\n135.0\n90\n\n\n46\nItaly\nSangiovese\n90.0\n90\n\n\n50\nItaly\nSangiovese\n100.0\n90\n\n\n...\n...\n...\n...\n...\n\n\n149186\nFrance\nBordeaux-style Red Blend\n85.0\n94\n\n\n149187\nFrance\nBordeaux-style Red Blend\n260.0\n94\n\n\n149299\nFrance\nBordeaux-style Red Blend\n100.0\n93\n\n\n149344\nFrance\nAlsace white blend\n95.0\n86\n\n\n149471\nFrance\nBordeaux-style Red Blend\n115.0\n91\n\n\n\n\n3025 rows × 4 columns\n\n\n\niloc uses integer locations instead\n\ndf.iloc[150929, 0] # English: Get the 150929th row and the 0th column \n\n'Italy'\n\n\n\n\nOperations on Data\n\n# Take the mean of the price column and round to two decimals\n# \ndf['points'].mean().round(2)\n\n87.89\n\n\n\n# Take the list of aggregations mean and median. Returns a series. \ndf['points'].agg(['mean', 'median'])\n\nmean      87.888418\nmedian    88.000000\nName: points, dtype: float64\n\n\n\ndf.loc[:,'points'].describe()\n\ncount    150930.000000\nmean         87.888418\nstd           3.222392\nmin          80.000000\n25%          86.000000\n50%          88.000000\n75%          90.000000\nmax         100.000000\nName: points, dtype: float64\n\n\nOr combine series objects and create new columns\n\n# Assign this new feature to a column.\ndf['point_price_ratio'] = (df['points'] / df['price'])\ndf[['points', 'price', 'point_price_ratio']].head()\n\n\n\n\n\n\n\n\npoints\nprice\npoint_price_ratio\n\n\n\n\n0\n96\n235.0\n0.408511\n\n\n1\n96\n110.0\n0.872727\n\n\n2\n96\n90.0\n1.066667\n\n\n3\n96\n65.0\n1.476923\n\n\n4\n95\n66.0\n1.439394\n\n\n\n\n\n\n\n\n\nMissing Values\n\n# Find missing values in price\ndf.loc[df['price'].isna()].head()\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\npoint_price_ratio\n\n\n\n\n32\nItaly\nUnderbrush, scorched earth, menthol and plum s...\nVigna Piaggia\n90\nNaN\nTuscany\nBrunello di Montalcino\nNaN\nSangiovese\nAbbadia Ardenga\nNaN\n\n\n56\nFrance\nDelicious while also young and textured, this ...\nLe Pavé\n90\nNaN\nLoire Valley\nSancerre\nNaN\nSauvignon Blanc\nDomaine Vacheron\nNaN\n\n\n72\nItaly\nThis offers aromas of red rose, wild berry, da...\nBussia Riserva\n91\nNaN\nPiedmont\nBarolo\nNaN\nNebbiolo\nSilvano Bolmida\nNaN\n\n\n82\nItaly\nBerry, baking spice, dried iris, mint and a hi...\nPalliano Riserva\n91\nNaN\nPiedmont\nRoero\nNaN\nNebbiolo\nCeste\nNaN\n\n\n116\nSpain\nAromas of brandied cherry and crème de cassis ...\nDulce Tinto\n86\nNaN\nLevante\nJumilla\nNaN\nMonastrell\nCasa de la Ermita\nNaN\n\n\n\n\n\n\n\nMissing values can be dropped or filled in (or left alone)\n\n# Drop any rows containing missing values\ndf.dropna().head()\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\npoint_price_ratio\n\n\n\n\n0\nUS\nThis tremendous 100% varietal wine hails from ...\nMartha's Vineyard\n96\n235.0\nCalifornia\nNapa Valley\nNapa\nCabernet Sauvignon\nHeitz\n0.408511\n\n\n2\nUS\nMac Watson honors the memory of a wine once ma...\nSpecial Selected Late Harvest\n96\n90.0\nCalifornia\nKnights Valley\nSonoma\nSauvignon Blanc\nMacauley\n1.066667\n\n\n3\nUS\nThis spent 20 months in 30% new French oak, an...\nReserve\n96\n65.0\nOregon\nWillamette Valley\nWillamette Valley\nPinot Noir\nPonzi\n1.476923\n\n\n8\nUS\nThis re-named vineyard was formerly bottled as...\nSilice\n95\n65.0\nOregon\nChehalem Mountains\nWillamette Valley\nPinot Noir\nBergström\n1.461538\n\n\n9\nUS\nThe producer sources from two blocks of the vi...\nGap's Crown Vineyard\n95\n60.0\nCalifornia\nSonoma Coast\nSonoma\nPinot Noir\nBlue Farm\n1.583333\n\n\n\n\n\n\n\n\n# Drop any rows where price or points are missing\ndf.dropna(subset=['price', 'points']).head()\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\npoint_price_ratio\n\n\n\n\n0\nUS\nThis tremendous 100% varietal wine hails from ...\nMartha's Vineyard\n96\n235.0\nCalifornia\nNapa Valley\nNapa\nCabernet Sauvignon\nHeitz\n0.408511\n\n\n1\nSpain\nRipe aromas of fig, blackberry and cassis are ...\nCarodorum Selección Especial Reserva\n96\n110.0\nNorthern Spain\nToro\nNaN\nTinta de Toro\nBodega Carmen Rodríguez\n0.872727\n\n\n2\nUS\nMac Watson honors the memory of a wine once ma...\nSpecial Selected Late Harvest\n96\n90.0\nCalifornia\nKnights Valley\nSonoma\nSauvignon Blanc\nMacauley\n1.066667\n\n\n3\nUS\nThis spent 20 months in 30% new French oak, an...\nReserve\n96\n65.0\nOregon\nWillamette Valley\nWillamette Valley\nPinot Noir\nPonzi\n1.476923\n\n\n4\nFrance\nThis is the top wine from La Bégude, named aft...\nLa Brûlade\n95\n66.0\nProvence\nBandol\nNaN\nProvence red blend\nDomaine de la Bégude\n1.439394\n\n\n\n\n\n\n\n\n# Filling in missing values\n# For the missing values in price, assign the mean price to it.\ndf_filled_in_price = df.loc[df['price'].isna(), 'price'] = df['price'].mean()\n\n\n\nString Methods\n\nPandas has a number of methods that allow you to work with string types\n\nFiltering\nManipulating\nConverting\nSubsetting\n\n\nExample: Find all entries containing the word aroma\n\ndf['description'].str.contains(\"aroma\").head()\n\n0    False\n1     True\n2    False\n3     True\n4    False\nName: description, dtype: bool\n\n\nreturns a description boolean series if the word aroma is in the description\n\n# Finding the entries in the dataframe\ndf.loc[df['description'].str.contains(\"aroma\")].head()\n\n\n\n\n\n\n\n\ncountry\ndescription\ndesignation\npoints\nprice\nprovince\nregion_1\nregion_2\nvariety\nwinery\npoint_price_ratio\n\n\n\n\n1\nSpain\nRipe aromas of fig, blackberry and cassis are ...\nCarodorum Selección Especial Reserva\n96\n110.0\nNorthern Spain\nToro\nNaN\nTinta de Toro\nBodega Carmen Rodríguez\n0.872727\n\n\n3\nUS\nThis spent 20 months in 30% new French oak, an...\nReserve\n96\n65.0\nOregon\nWillamette Valley\nWillamette Valley\nPinot Noir\nPonzi\n1.476923\n\n\n6\nSpain\nSlightly gritty black-fruit aromas include a s...\nSan Román\n95\n65.0\nNorthern Spain\nToro\nNaN\nTinta de Toro\nMaurodos\n1.461538\n\n\n7\nSpain\nLush cedary black-fruit aromas are luxe and of...\nCarodorum Único Crianza\n95\n110.0\nNorthern Spain\nToro\nNaN\nTinta de Toro\nBodega Carmen Rodríguez\n0.863636\n\n\n10\nItaly\nElegance, complexity and structure come togeth...\nRonco della Chiesa\n95\n80.0\nNortheastern Italy\nCollio\nNaN\nFriulano\nBorgo del Tiglio\n1.187500\n\n\n\n\n\n\n\n\n# Get the first 10 characters for each of the \ndf['description'].str[:10].head()\n\n0    This treme\n1    Ripe aroma\n2    Mac Watson\n3    This spent\n4    This is th\nName: description, dtype: object\n\n\n\n# Join the first 10 chars and last 10 chars together \n# Wrap in parenthesis if chaining methods\n(df['description'].str[:10] + df['description'].str[-10:]).head()\n\n0    This treme2022–2030.\n1    Ripe aromaough 2023.\n2    Mac Watsonual sugar.\n3    This spentough 2032.\n4    This is thfrom 2020.\nName: description, dtype: object\n\n\n\n\nData Grouping\n\nWhat if we wanted to know the average points per country?\nWe need a tool to group categories together and perform operations.\n\n\nSplit-Apply-Combine\n\n\n# Break the Dataframe into a smaller Dataframe for each country label\n# Calculate the mean in each Dataframe \n\ndf.groupby('country')['points'].mean().head(3)\n\ncountry\nAlbania      88.000000\nArgentina    85.996093\nAustralia    87.892475\nName: points, dtype: float64\n\n\n\n# groupby example \n# Returns a series of mean points per country and province\ndf.groupby(['country', 'province'])['points'].mean().head()\n\ncountry    province        \nAlbania    Mirditë             88.000000\nArgentina  Mendoza Province    86.108182\n           Other               85.398200\nAustralia  Australia Other     84.813743\n           New South Wales     87.048780\nName: points, dtype: float64\n\n\n\ndf.groupby(['country', 'province'])['points', 'price'].mean().head()\n\n\n\n\n\n\n\n\n\npoints\nprice\n\n\ncountry\nprovince\n\n\n\n\n\n\nAlbania\nMirditë\n88.000000\n20.000000\n\n\nArgentina\nMendoza Province\n86.108182\n20.951441\n\n\nOther\n85.398200\n20.570362\n\n\nAustralia\nAustralia Other\n84.813743\n11.770819\n\n\nNew South Wales\n87.048780\n22.139280"
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#data-visualization",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#data-visualization",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "Data Visualization",
    "text": "Data Visualization\nLets take the top 3 wine varieties and look at some visualization examples using plotly.\n\ndef select_by_top(_df, cat, n):\n    return ( _df[cat]\n            .value_counts()[:n]\n            .index\n            .tolist()\n           ) \n\n\nvis_df = df.loc[df['variety'].isin(select_by_top(df,'variety', 3)),]\nvis_df = vis_df.dropna()\n\n\nHistograms and Bars\nPreparing the data for counting\n\ncount_df = ( vis_df\n            .groupby('variety')\n            .size() # Count the amount of rows in the group\n            .rename('count') # Name the series count\n            .reset_index() # Set the group index as a column and create a new index\n            ) \n\n\ncount_df\n\n\n\n\n\n\n\n\nvariety\ncount\n\n\n\n\n0\nCabernet Sauvignon\n4889\n\n\n1\nChardonnay\n4892\n\n\n2\nPinot Noir\n7442\n\n\n\n\n\n\n\n\nSeabornPlotly\n\n\n\nax=sns.barplot(data=count_df, x='variety', y='count')\nax.set_title(\"Counting Variety\")\nplt.show()\n\n\n\n\n\n\n\npx.bar(count_df, x='variety', y='count', title='Counting Variety')\n\n\n                                                \n\n\n\n\n\nBreaking down by province\n\ncount_reg_df = ( vis_df\n            .groupby(['variety', 'province']) \n            .size() # Count the amount of rows in the group\n            .rename('count') # Name the series count\n            .reset_index() # Set the group index as a column and create a new index\n) \n\n\ncount_reg_df\n\n\n\n\n\n\n\n\nvariety\nprovince\ncount\n\n\n\n\n0\nCabernet Sauvignon\nCalifornia\n4040\n\n\n1\nCabernet Sauvignon\nNew York\n29\n\n\n2\nCabernet Sauvignon\nOregon\n42\n\n\n3\nCabernet Sauvignon\nWashington\n778\n\n\n4\nChardonnay\nCalifornia\n3992\n\n\n5\nChardonnay\nNew York\n275\n\n\n6\nChardonnay\nOregon\n239\n\n\n7\nChardonnay\nWashington\n386\n\n\n8\nPinot Noir\nCalifornia\n5424\n\n\n9\nPinot Noir\nNew York\n48\n\n\n10\nPinot Noir\nOregon\n1961\n\n\n11\nPinot Noir\nWashington\n9\n\n\n\n\n\n\n\n\nSeabornPlotly\n\n\n\nsns.barplot(data=count_reg_df, x='variety', y='count', hue='province');\n\n\n\n\n\n\n\npx.bar(count_reg_df, x='variety', y='count', color='province', title='Most Popular Varieties Count by Province' )\n\n\n                                                \n\n\n\n\n\n\n\nBox and Violin Plots\n\nSeabornPlotly\n\n\n\nax=sns.boxplot(data=vis_df, x='variety', y='price')\nax.set_title(\"Price Dist by Variety\")\nplt.show()\n\n\n\n\n\n\n\npx.box(vis_df, x='variety', y='price', title='Price Dist. By Variety')\n\n\n                                                \n\n\n\n\n\nHard to read? Zoom in!\n\nSeabornPlotly\n\n\n\nax=sns.violinplot(data=vis_df, x='variety', y='price')\nax.set_ylim(-3,300)\nax.set_title(\"Price Dist. by Variety\")\nplt.show()\n\n\n\n\n\n\n\npx.violin(vis_df, x='variety', y='price', title='Price Dist. By Variety', range_y=[-3,300])\n\n\n                                                \n\n\n\n\n\n\n\nECDF Plots\nVisualizing the empirical cumulative density function (ECDF)\n\nSeabornPlotly\n\n\n\nax = sns.ecdfplot(data=vis_df, x='price', hue='variety')\nax.set_title(\"ECDF Plot of Price by Variety\")\n\nText(0.5, 1.0, 'ECDF Plot of Price by Variety')\n\n\n\n\n\n\n\n\npx.ecdf(vis_df,x='price', color='variety', title='ECDF Plot of Price by Variety')\n\n\n                                                \n\n\n\n\n\n\n\nScatterplots\nPlotting Relationships\n\nSeabornPlotly\n\n\n\nax = sns.scatterplot(data=vis_df, x='price', y='points')\nax.set_title('Wine Price vs. Wine Rating')\nplt.show()\n\n\n\n\n\n\n\nfig = px.scatter(vis_df, x='price', y='points', title='Wine Price vs. Wine Rating')\nfig.show()\n\n\n                                                \n\n\n\n\n\nThis is looking a little cramped. Let’s try log scaling these plots.\n\nSeabornPlotly\n\n\n\nax = sns.scatterplot(data=vis_df, x='price', y='points')\nax.set_xscale('log')\nax.set_title(\"Wine Price vs. Wine Rating\")\nplt.show()\n\n\n\n\n\n\n\nfig = px.scatter(vis_df, x='price', y='points', title='Wine Price vs. Wine Rating', log_x=True)\nfig.show()\n\n\n                                                \n\n\n\n\n\nAdding Color\n\nSeabornPlotly\n\n\n\n#Adding Color\nax = sns.scatterplot(data=vis_df, x='price', y='points', hue='variety')\nax.set_xscale('log')\nax.set_title(\"Wine Price vs. Wine Rating\")\nplt.show()\n\n\n\n\n\n\n\nfig = px.scatter(vis_df, x='price', y='points', color='variety',title='Wine Price vs. Wine Rating', log_x=True, opacity=0.25)\nfig.show()\n\n\n                                                \n\n\n\n\n\n\n\nTrends\nAdding a Trendline\n\nSeabornPlotly\n\n\n\nfig = px.scatter(vis_df,\n                 x='price',\n                 y='points',\n                 title='Wine Price vs. Wine Rating',\n                 log_x=True,\n                 opacity=0.2,\n                 trendline='lowess')\nfig.show()\n\n\n                                                \n\n\n\n\n\nax = sns.regplot(data=vis_df, x='price', y='points', lowess=True, scatter_kws={'alpha': 0.1}, line_kws={'color': 'green'})\nax.set_xscale('log')\nax.set_title(\"Wine Price vs. Wine Rating\")\nplt.show()\n\n\n\n\n\n\n\nLooks good! But how do these trends change by variety? What about province?\n\n\nFaceting\nFaceting allow for visualizing by a group.\nWe can combine everything we’ve learned thus far into a a single figure.\n\nSeabornPlotly\n\n\n\nfig = px.scatter(vis_df,\n                 x='price',\n                 y='points',\n                 hover_data=['winery'],\n                 facet_col='variety',\n                 title='Wine Price vs. Wine Rating by Variety',\n                 log_x=True,\n                 opacity=0.2,\n                 trendline='lowess',\n                 facet_row='province',)\nfig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"province=\", \"\")))# Cleaning up the row facets \nfig.show()\n\n\n                                                \n\n\n\n\n\ng = ( sns.lmplot(\n    data=vis_df, x='price', y='points', col='variety',\n     row='province', lowess=True, line_kws={'color':'green'},\n      scatter_kws={'alpha': 0.2}, facet_kws={'subplot_kws': {'xscale': 'log'}, 'margin_titles': True})\n    )\ng.set_titles(row_template = '{row_name}', col_template = '{col_name}')\nplt.show()"
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#seaborn-vs.-plotly-pro-cons",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#seaborn-vs.-plotly-pro-cons",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "Seaborn Vs. Plotly Pro / Cons",
    "text": "Seaborn Vs. Plotly Pro / Cons\nPlotly Pros:\n- Interactivity right out of the box. No assembly required!\n- Great for dashboarding.\n- Plotly express makes taking in pandas dataframes work well out of the box. \nPlotly Cons:\n- Newer and less mature than seaborn/matplotlib. May be harder to problem solve / debug. \nSeaborn Pros:\n\nMatplotlib backend is more performant when plotting a lot of data.\nMatplotlib backend is very mature and it’s fairly easy to google your way into the plot you want.\n\nSeaborn Cons:\n- Interactivity is more challenging to implement.\n- API is complex and takes time to master when making customized plots."
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#tips",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#tips",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "Tips",
    "text": "Tips\n\nKeep the number of intermediate DataFrames to a minimum\n\nHaving too many variables can confuse the reader and analyst. (Did I perform this operation on df85 or df86?)\nMethod chaining can help reduce the number of intermediate variables.\n\nCheck your work!\n\nIts very possible to screw up your data without realizing you have.\nBefore you show your conclusions to stakeholders, perform some reasonable data checks.\n\nPick a data vis tool and stick to it.\n\nEach takes a bit of time to master, and can be confusing to try and learn multiple data vis tools at once.\n\nThese tools have a lot of functionality and are complicated. Don’t be afraid to google if you can’t remember how to do something."
  },
  {
    "objectID": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#resources",
    "href": "posts/post-with-code/intro_to_pandas_mpl/intro_pandas_matplotlib.html#resources",
    "title": "Data Analysis with Pandas, Plotly and Seaborn - Part 1",
    "section": "Resources",
    "text": "Resources\n\nSeaborn API: https://seaborn.pydata.org/api.html\nGetting Started with Matplotlib: https://pythonprogramming.net/matplotlib-python-3-basics-tutorial/\nPandas user guide https://pandas.pydata.org/docs/user_guide/index.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A data science blog",
    "section": "",
    "text": "Working With Polars\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ndata viz\n\n\n\n\nComparing the speed of polars vs pandas\n\n\n\n\n\n\nAug 1, 2023\n\n\nJordan Wilheim\n\n\n\n\n\n\n  \n\n\n\n\nData Analysis with Pandas, Plotly and Seaborn - Part 1\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ndata viz\n\n\n\n\nAn introduction to data analytics in python\n\n\n\n\n\n\nAug 1, 2023\n\n\nJordan Wilheim\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\nJordan Wilheim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/bikeshare/bikeshare.html",
    "href": "posts/post-with-code/bikeshare/bikeshare.html",
    "title": "Working With Polars",
    "section": "",
    "text": "import pandas as pd\nfrom glob import glob\nimport polars as pl\nimport requests\nimport plotly.express as px\nimport seaborn as sns\n\nsns.set()\n\n\nPandasPolars\n\n\n\ndf = (pd\n .concat([pd.read_csv(data) for data in glob(\"data/2*\")])\n .assign(started_at = lambda x: pd.to_datetime(x.started_at).dt.tz_localize(\"US/Central\", ambiguous=True)\n         , ended_at = lambda x: pd.to_datetime(x.ended_at).dt.tz_localize(\"US/Central\", ambiguous=True)\n         , is_member = lambda x: x.member_casual == 'member'\n         )\n           )\n\n\n\n\ndf = (\n    pl.scan_csv(\n        \"data/*\",\n        dtypes={\n            \"start_station_id\": str,\n            \"end_station_id\": str,\n            \"started_at\": pl.Datetime(time_zone=\"US/Central\"),\n            \"ended_at\": pl.Datetime(time_zone=\"US/Central\"),\n        },\n    )\n    .with_columns((pl.col(\"member_casual\") == \"member\").alias(\"is_member\"))\n    .collect()\n)\n\n\n\n\n\ndate_min, date_max = (\n    str(df.get_column(\"started_at\").min()).split(\" \")[0],\n    str(df.get_column(\"started_at\").max()).split(\" \")[0],\n)\n\n\nmystery_lat, mystery_long = 41.960000, -87.680000\n\nresp = requests.get(\n    f\"https://archive-api.open-meteo.com/v1/archive?latitude={mystery_lat}&longitude={mystery_long}&start_date={date_min}&end_date={date_max}&hourly=temperature_2m&temperature_unit=fahrenheit\"\n)\n\ntime_df = pl.DataFrame(\n    resp.json()[\"hourly\"], schema={\"time\": str, \"temperature_2m\": float}\n).with_columns(\n    pl.col(\"time\").str.to_datetime(time_zone=\"UTC\").dt.convert_time_zone(\"US/Central\")\n)\n\n\nPandasPolars\n\n\n\n(\n    df.to_pandas()\n    .set_index(\"started_at\")\n    .groupby(\"is_member\")\n    .ride_id.resample(\"30D\")\n    .count()\n    .unstack(0)\n    .plot()\n);\n\n\n\n\n\n\n\npx.line(\n    df.sort(\"started_at\")\n    .join_asof(time_df.sort(by=\"time\"), left_on=\"started_at\", right_on=\"time\")\n    .groupby_dynamic(\"started_at\", every=\"30d\", by=\"is_member\")\n    .agg(\n        [\n            pl.col(\"start_station_id\").count().alias(\"number_of_rides\"),\n            pl.col(\"temperature_2m\").mean().alias(\"avg temp\"),\n        ]\n    ),\n    x=\"started_at\",\n    y=\"number_of_rides\",\n    color=\"is_member\",\n    title=\"Bike Share Rides by membership\",\n)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "I’m renewing my blog in an attempt to learn by posting and post some of the things that I’ve found useful for my career as a data scientist."
  }
]